hidden_size: 64                  # (int) The number of features in the hidden state
hidden_dropout_prob: 0.5         # (float) The probability of an element to be zeroed.
layer_norm_eps: 1e-12            # (float) A value added to the denominator for numerical stability.
hidden_act: 'gelu'               # (str) The activation function in feed-forward layer.
num_hidden_layers: 2                # (int) The number of transformer layers in transformer encoder.
loss_type: 'CE'                  # (str) The type of loss function.
initializer_range: 0.02          # (float) The standard deviation for normal initialization.